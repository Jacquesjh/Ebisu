{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    data = clean_data(data = data)\n",
    "\n",
    "    data = filter_1(data = data)\n",
    "    data = filter_2(data = data)\n",
    "    data = filter_3(data = data)\n",
    "    ...\n",
    "\n",
    "    weights = optimizer(data = data)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_1(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Reduces the columns of the data dataframe\n",
    "    \"\"\"\n",
    "    top_tickers = ...\n",
    "    top_dataframe = rebuild_dataframe(raw_df = data, top_tickers = top_tickers)\n",
    "\n",
    "    return top_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_2(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_3(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Returns a dataframe of weights.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_dataframe(raw_df: pd.DataFrame, top_tickers: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        To keep the levels of the dataframe.\n",
    "    \"\"\"\n",
    "    processed_df = dict()\n",
    "\n",
    "    for level in raw_df.columns.levels[0]:\n",
    "        processed_df.update({level: raw_df[level][top_tickers]})\n",
    "\n",
    "    return pd.concat(processed_df, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(data: pd.DataFrame, start_date: datetime, rebalance_interval: str) -> List[datetime]:\n",
    "    \"\"\"\n",
    "        Returns a list of the date that a rebalance must occur.\n",
    "    \"\"\"\n",
    "    table = {\n",
    "        \"daily\"   : get_daily_dates,\n",
    "        \"weekly\"  : get_weekly_dates,\n",
    "        \"biweekly\": get_biweekly_dates,\n",
    "        \"monthly\" : get_monthly_dates\n",
    "    }\n",
    "\n",
    "    dates = table.get(rebalance_interval)(data = data, start_date = start_date)\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "def get_daily_dates(data: pd.DataFrame, start_date: datetime) -> list:\n",
    "    dates = pd.to_datetime(data.index[data.index > start_date])\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "def get_weekly_dates(data: pd.DataFrame, start_date: datetime) -> list:\n",
    "    dates = get_daily_dates(data = data, start_date = start_date)\n",
    "    dates = pd.to_datetime([date for date in dates if date.weekday() == 0])\n",
    "    \n",
    "    return dates\n",
    "\n",
    "\n",
    "def get_biweekly_dates(data: pd.DataFrame, start_date: datetime) -> list:\n",
    "    dates = get_weekly_dates(data = data, start_date = start_date)\n",
    "    dates = dates[:: 2]                                                         # deletes every other date\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "def get_monthly_dates(data: pd.DataFrame, start_date: datetime) -> list:\n",
    "    dates = get_biweekly_dates(data = data, start_date = start_date)\n",
    "    dates = dates[:: 2]\n",
    "\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns(data: pd.DataFrame, weights: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        Returns a condensed \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(data: pd.DataFrame, start_date: datetime, rebalance_interval: str) -> pd.DataFrame:\n",
    "    weights = pd.DataFrame()\n",
    "\n",
    "    dates = get_dates(data = data, start_date = start_date, rebalance_interval = rebalance_interval)\n",
    "\n",
    "    for date in dates:\n",
    "        date_weights = pipeline(data = data.loc[: date])\n",
    "        weights = pd.concat([weights, date_weights], axis = 1)\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    cleaned_data = interpolate_data(data = data)\n",
    "    cleaned_data = remove_outliers(data = data)\n",
    "    cleaned_data = remove_splits(data = data)\n",
    "    ...\n",
    "    \n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_splits(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_young_tickers(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(...)\n",
    "\n",
    "weights = backtest(data = data)\n",
    "returns = get_returns(data = data, weights = weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quantstats as qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs.plots.snapshot(returns = returns, title = \"Portfolio Performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('research-0MDvmO17-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fd9bcd5fc85e1dbf083a295d7ebca2be267dd81b1cd67b6b9405cc403d92ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
